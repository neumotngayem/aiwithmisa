---
layout: post
title: "[L√Ω Thuy·∫øt] B√†i 7 H·ªìi quy Logistic - Logistic Regression"
subtitle: "Lo·∫°t b√†i h·ªçc thu·ªôc series AML"
date: 2020-12-14
author: "KyoHB"
header-img: "img/post-bg-aml.jpg"
tags: [AML]
---

Qua b√†i 4 v√† 5 ch√∫ng ta ƒë√£ t√¨m hi·ªÉu v√† th·ª±c h√†nh v·ªÅ Supervised ML model ƒë·∫ßu ti√™n - Linear Regression model, nh·∫±m gi·∫£i quy·∫øt c√°c b√†i to√°n regression. H√¥m nay ch√∫ng ta s·∫Ω t√¨m hi·ªÉu v·ªÅ 
Logistic Regression model, ƒë√¢y l√† m·ªôt linear model gi√∫p gi·∫£i quy·∫øt c√°c b√†i to√°n classification v√≠ d·ª• nh∆∞ ph√¢n lo·∫°i ·ªëm hay kh·ªèe m·∫°nh, gian l·∫≠n hay kh√¥ng gian l·∫≠n,..

## ƒê∆∞·ªùng ph√¢n ƒë·ªãnh - Decision boundary

Trong b√†i to√°n ph√¢n lo·∫°i, ch√∫ng ta c·∫ßn Logistic Regression t·∫°o ra m·ªôt ƒë∆∞·ªùng ph√¢n ƒë·ªãnh (decision boundary) gi√∫p ph√¢n lo·∫°i c√°c nh√≥m (class) c·ªßa d·ªØ li·ªáu nh∆∞ h√¨nh m√¥ t·∫£ d∆∞·ªõi ƒë√¢y:

![]({{ site.baseurl }}/img/in-post/aml/logistic-regression.png)*Source: cs.tufts.edu*
{:.image-caption}

H√†m s·ªë tuy·∫øn t√≠nh (linear function) ch√∫ng ta mong mu·ªën s·∫Ω l√†:

$score = w_{0} + w_{1}x$
{:.formula}

S·ª± kh√°c bi·ªát c·ªßa h√†m s·ªë tuy·∫øn t√≠nh (linear function) tr√™n v·ªõi h√†m s·ªë c·ªßa Linear Regression n·∫±m ·ªü b√™n v·∫ø tr√°i, gi√° tr·ªã c·ªßa bi·∫øn kh√¥ng ph·ª• thu·ªôc (dependent variable) y gi·ªù ƒë∆∞·ª£c thay b·∫±ng score, v·∫≠y score n√†y l√† g√¨ ? Score n√†y ƒë∆∞·ª£c k·ª≥ v·ªçng s·∫Ω gi√∫p ch√∫ng ph√¢n lo·∫°i c√° th·ªÉ (instance) v√†o c√°c nh√≥m (class). ·ªû ƒë√¢y ch√∫ng ta s·∫Ω ƒë·ªÉ √Ω ƒë·∫øn 2 th·ª©:

1. D·∫•u c·ªßa score, d·∫•u c·ªßa score s·∫Ω ch√∫ng ta bi·∫øt nh√≥m (class) c·ªßa c√° th·ªÉ (instance). Gi·∫£ s·ª≠ ch√∫ng ta c√≥ 2 nh√≥m (class) l√† -1 v√† 1. N·∫øu d·∫•u c·ªßa score l√† √¢m th√¨ n√≥ s·∫Ω thu·ªôc v·ªÅ nh√≥m (class) -1 v√† d·∫•u l√† d∆∞∆°ng th√¨ n√≥ s·∫Ω thu·ªôc v·ªÅ nh√≥m (class) 1.
2. ƒê·ªô l·ªõn c·ªßa score, ch√∫ng ta c√≥ th·ªÉ th·∫•y nh·ªØng c√° th·∫ø (instance)c√†ng xa ƒë∆∞·ªùng ph√¢n ƒë·ªãnh (decision boundary) c√†ng ch·∫Øc ch·∫Øn ƒëi·ªÉm ƒë√≥ thu·ªôc v·ªÅ nh√≥m (class) ƒë√≥. C√°c c√° th·∫ø (instance) ·ªü c√†ng g·∫ßn ƒë∆∞·ªùng ph√¢n ƒë·ªãnh, t∆∞∆°ng ·ª©ng v·ªõi score b·∫±ng 0 s·∫Ω c√≥ th·ªÉ thu·ªôc v·ªÅ 1 trong 2 nh√≥m (class), v√† nh·ªØng ƒëi·ªÉm n√†y l√† nh·ªØng ƒëi·ªÉm kh√° m∆° h·ªì (confuse), ·ªü h√¨nh tr√™n ch√∫ng ta th·∫•y c√≥ m·ªôt v√†i c√° th·ªÉ (instance) thu·ªôc nh√≥m (class) xanh nh∆∞ng thu·ªôc khu v·ª±c c·ªßa nh√≥m (class) ƒë·ªè v√† ng∆∞·ª£c l·∫°i. 


![]({{ site.baseurl }}/img/in-post/aml/score-logistic.png)*Source: coursera.org*
{:.image-caption}

## H√†m Logistic - Logistic function

Tuy nhi√™n score kh√¥ng th·ªÉ l√†m ch√∫ng ta h√†i l√≤ng, ƒëi·ªÅu ch√∫ng ta mu·ªën l√† x√°c xu·∫•t (probability) c·ªßa c√° th·ªÉ (instance) n√†y thu·ªôc v·ªÅ nh√≥m (class) l√† bao nhi√™u ph·∫ßn trƒÉm. Do ƒë√≥, score s·∫Ω ƒë∆∞·ª£c ƒë∆∞a v√†o logistic function, hay t√™n g·ªçi kh√°c ƒë√≥ l√† softmax c·ªßa score. Softmax trong tr∆∞·ªùng h·ª£p ch·ªâ c√≥ 2 nh√≥m (class) - binary classification c√≤n ƒë∆∞·ª£c g·ªçi l√† Sigmoid. V·∫≠y h√†m s·ªë Sigmoid (Sigmoid function) c√≥ t√°c d·ª•ng g√¨ ?

![]({{ site.baseurl }}/img/in-post/aml/sigmoid.png)*Source: coursera.org*
{:.image-caption}

Sigmoid s·∫Ω chuy·ªÉn ƒë·ªïi score ch√∫ng ta c√≥ ƒë∆∞·ª£c ·ªü tr√™n, th√†nh x√°c su·∫•t (probability) c·ªßa c√° th·ªÉ ƒë√≥ thu·ªôc nh√≥m (class) 1, k√Ω hi·ªáu l√† $P(y = 1\| x_{i}, w)$. Trong ƒë√≥ $x_{i}$, $w$ ch√≠nh l√† bi·ªÉu th·ªã c·ªßa h√†m s·ªë tuy·∫øn t√≠nh $w_{0} + w_{1}x$, k√Ω hi·ªáu tr√™n ƒë∆∞·ª£c hi·ªÉu l√† x√°c xu·∫•t c·ªßa c√° th·ªÉ (instance) thu·ªôc nh√≥m (class) 1 v·ªõi  h√†m s·ªë tuy·∫øn t√≠nh (linear function) ƒë√£ cho (given). Th√¥ng th∆∞·ªùng ch√∫ng ta s·∫Ω ƒë·∫∑t 0.5 l√† ng∆∞·ª°ng (Threshold) nh∆∞ ƒë√£ ƒë·ªÅ c·∫≠p ·ªü b√†i s·ªë 3, n·∫øu x√°c xu·∫•t (probability) l·ªõn h∆°n 0.5 ch√∫ng ta s·∫Ω quy ƒë·ªãnh c√° th·ªÉ (instance) thu·ªôc nh√≥m class (1), n·∫øu nh·ªè h∆°n s·∫Ω thu·ªôc nh√≥m (class) 0. ƒê·ªÉ h√¨nh d√πng c·ª• th·ªÉ h∆°n v·ªÅ c√°ch Sigmoid chuy·ªÉn ƒë·ªïi Score th√†nh x√°c su·∫•t (probability) ch√∫ng ta h√£y xem c√¥ng th·ª©c c·ªßa h√†m s·ªë Sigmoid, c≈©ng nh∆∞ ƒë·ªì th·ªã c·ªßa n√≥.

$P(y = 1\| x_{i}, w) = \frac{1}{1+e^{-score}}$
{:.formula}

![]({{ site.baseurl }}/img/in-post/aml/sigmoid-plot.png)*Source: coursera.org*
{:.image-caption}

C√≥ th·ªÉ th·∫•y ƒë·∫∑c ch∆∞ng c·ªßa Sigmoid function ƒë√≥ l√† b√£o h√≤a (saturate) ·ªü 0 v√† 1 khi c√°c gi√° tr·ªã c·ªßa score c√†ng l·ªõn ho·∫∑c c√†ng nh·ªè, gi√∫p chuy·ªÉn ƒë·ªïi score ra x√°c xu·∫•t (probability) m√† ch√∫ng ta mong mu·ªën.

# H√†m m·∫•t m√°t - Loss function

ƒê·ªëi v·ªõi c√°c b√†i to√°n ph√¢n lo·∫°i (classification), h√†m m·∫•t m√°t (loss function) th∆∞·ªùng ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë√≥ l√† cross entropy loss. 

$cross\,\,entropy\,\,loss = -\frac{1}{n} \sum_{1}^{n}y_{i}\, log \left ( p(x_{i}) \right ) + (1 - y_{i})\, log \left ( 1 -p(x_{i}) \right )$
{:.formula}

Trong ƒë√≥ n l√† s·ªë c√° th·ªÉ (instance) c·ªßa t·∫≠p d·ªØ li·ªáu

ƒê·ªÉ hi·ªÉu c√°ch ho·∫°t ƒë·ªông c·ªßa cross entropy loss, ch√∫ng ta h√£y c√πng x√©t tr∆∞·ªùng h·ª£p sau. Ch√∫ng ta c√≥ c√° th·ªÉ (instance) thu·ªôc nh√≥m (class) 1, t∆∞∆°ng ·ª©ng v·ªõi $y_{i}$ b·∫±ng 1, tuy nhi√™n Logistic regression model c·ªßa ch√∫ng ta l·∫°i d·ª± ƒëo√°n $p(x_{i})$ b·∫±ng 0, khi ƒë√≥ $log (p(x_{i}))$ t∆∞∆°ng ·ª©ng v·ªõi $log (0)$ v√† c√≥ gi√° tr·ªã √¢m v√¥ c√πng, loss c·ªßa ch√∫ng ta s·∫Ω r·∫•t l·ªõn, ch·ª©ng t·ªè model ƒëang d·ª± ƒëo√°n sai. ƒêi·ªÅu t∆∞∆°ng t·ª± s·∫Ω x·∫£y ra trong tr∆∞·ªùng h·ª£p c√° th·ªÉ thu·ªôc nh√≥m (class) 0, nh∆∞ng l·∫°i ƒë∆∞·ª£c d·ª± ƒëo√°n v·ªõi x√°c su·∫•t l√† 1. 

# K·∫øt

C√≥ th·ªÉ th·∫•y h·ªìi quy Logistic - Logistic Regression l√† m·ªôt bi·∫øn th·ªÉ c·ªßa h·ªìi quy tuy·∫øn t√≠nh Linear Regression gi·∫£i quy·∫øt ph√¢n lo·∫°i (classification) d·ªØ li·ªáu. Hai ML model n√†y c√°c t√≠nh ch·∫•t t∆∞∆°ng ƒë∆∞∆°ng nhau. ·ªû b√†i ti·∫øp theo ch√∫ng ta s·∫Ω th·ª±c h√†nh tri·ªÉn khai m·ªôt Logistic Regression model b·∫±ng Python, h√£y ƒë√≥n ƒë·ªçc nh√© üí™ .
