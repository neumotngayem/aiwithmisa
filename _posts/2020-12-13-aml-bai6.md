---
layout: post
title: "[Thực Hành] Bài 6 Hồi quy tuyến tính - Linear Regression"
subtitle: "Loạt bài học thuộc series AML"
date: 2020-12-13
author: "KyoHB"
header-img: "img/post-bg-aml.jpg"
tags: [AML]
---

Chúng ta sẽ cùng thực hành triển khai huấn luyện (training) một Linear Regression model cho một bài toán dự đoán giá nhà nhé !


<span style='color: #f44336'>* Các bài thực hành đều sử dụng Python 3.</span>


# **Import tập dữ liệu**

Tập dữ liệu (dataset) được sử dụng trong bài thực hành này là tập dữ liệu (dataset) ở link sau:



[Download Tập dữ liệu](https://www.kaggle.com/quantbruce/real-estate-price-prediction)


```python
import pandas as pd
```


```python
df = pd.read_csv('Real estate.csv', index_col=0)
df
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X1 transaction date</th>
      <th>X2 house age</th>
      <th>X3 distance to the nearest MRT station</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
      <th>Y house price of unit area</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>2012.917</td>
      <td>32.0</td>
      <td>84.87882</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
      <td>37.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2012.917</td>
      <td>19.5</td>
      <td>306.59470</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
      <td>42.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2013.583</td>
      <td>13.3</td>
      <td>561.98450</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>47.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2013.500</td>
      <td>13.3</td>
      <td>561.98450</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>54.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>2012.833</td>
      <td>5.0</td>
      <td>390.56840</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
      <td>43.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>410</th>
      <td>2013.000</td>
      <td>13.7</td>
      <td>4082.01500</td>
      <td>0</td>
      <td>24.94155</td>
      <td>121.50381</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>411</th>
      <td>2012.667</td>
      <td>5.6</td>
      <td>90.45606</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>50.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>2013.250</td>
      <td>18.8</td>
      <td>390.96960</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>413</th>
      <td>2013.000</td>
      <td>8.1</td>
      <td>104.81010</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
      <td>52.5</td>
    </tr>
    <tr>
      <th>414</th>
      <td>2013.500</td>
      <td>6.5</td>
      <td>90.45606</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>63.9</td>
    </tr>
  </tbody>
</table>
<p>414 rows × 7 columns</p>
</div>



Tập dữ liệu (dataset) này bao gồm 414 cá thể (instance) bao gồm có 6 biến không phụ thuộc (independent variable) và một biến phụ thuộc (dependent variable) đó là giá một $m^{2}$ nhà.

# **Tiền xử lý dữ liệu**

Một trong những công việc quan trọng khi huấn luyện (training) Linear Regression model đó là chúng ta cần xem sự tương quan (correlation) giữa các biến không phụ thuộc (independent variable) và biến phụ thuộc (dependent variable), cũng nhưng giữa các biến không phụ thuộc (independent variable).


```python
import seaborn as sns

import matplotlib.pyplot as plt
```


```python
corr_matrix = df.corr()

sns.heatmap(corr_matrix, annot=True)

plt.show()
```


![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_9_0.png)


Qua ma trận tương quan (correlation matrix) trên chúng ta có thể thấy biến không phụ thuộc (independent variable) X1 transaction date, gần như không có tác động gì đến giá nhà, mức độ tương quan gần như bằng 0 (0.087), chúng ta sẽ loại bỏ biến không phụ thuộc này. Nhìn vào ma trận tương quan (correlation matrix) này chúng ta cũng thấy những vấn đề rất logic: giá nhà sẽ tăng nếu tuổi thọ ngôi nhà thấp (X2 house age có mức độ tương quan với giá nhà là -0.21), nhà càng xa trạm tàu điện thì giá nhà cũng càng giảm (X3 distance to the nearest MRT station có mức độ tương quan với giá nhà là -0.67), số lượng cửa hàng tiện lợi càng nhiều thì giá nhà càng tăng (X4 number of convenience stores có mức độ tương quan với giá nhà là 0.57). Tuy nhiên biến không phụ thuộc X3 distance to the nearest MRT station cũng lại có mức độ tương quan cao với các biến khác, tạo ra nguy cơ cộng tuyến (collinearity) cho Linear Regression model, do đó chúng ta cũng cần phải loại bỏ biến này.


```python
df_new = df.drop(df.columns[[0,2]], axis=1)

df_new
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X2 house age</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
      <th>Y house price of unit area</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.0</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
      <td>37.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.5</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
      <td>42.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>47.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>54.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.0</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
      <td>43.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>410</th>
      <td>13.7</td>
      <td>0</td>
      <td>24.94155</td>
      <td>121.50381</td>
      <td>15.4</td>
    </tr>
    <tr>
      <th>411</th>
      <td>5.6</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>50.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>18.8</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>413</th>
      <td>8.1</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
      <td>52.5</td>
    </tr>
    <tr>
      <th>414</th>
      <td>6.5</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>63.9</td>
    </tr>
  </tbody>
</table>
<p>414 rows × 5 columns</p>
</div>



Cùng kiểm tra xem có dữ liệu trống (missing value) ở tập dữ liệu này (dataset) này không nhé.


```python
import missingno as msno
```


```python
x = df_new.iloc[:,0:4]

x
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X2 house age</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.0</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.5</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.0</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>410</th>
      <td>13.7</td>
      <td>0</td>
      <td>24.94155</td>
      <td>121.50381</td>
    </tr>
    <tr>
      <th>411</th>
      <td>5.6</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
    </tr>
    <tr>
      <th>412</th>
      <td>18.8</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
    </tr>
    <tr>
      <th>413</th>
      <td>8.1</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
    </tr>
    <tr>
      <th>414</th>
      <td>6.5</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
    </tr>
  </tbody>
</table>
<p>414 rows × 4 columns</p>
</div>




```python
msno.bar(x)
```



![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_15_1.png)


Không có giá trị trống (missing value) trong tập dữ liệu (dataset) của chúng ta.

Bước tiếp theo chúng ta sẽ kiểm tra xem có giá trị ngoại biên (outlier) trong tập dữ liệu (dataset) không nhé. Giá trị ngoại biên (outlier) là một giá trị lớn hơn hoặc nhỏ hơn hẳn so với các cá thể (instance) trong tập dữ liệu (dataset), các giá trị này vô hình chung là cho sai lệch trong quá trình huấn luyện (training) ML model. Ví dụ minh họa cho outlier trong một tập dữ liệu (Hãy nhìn vào số liệu của các Player khác và Player 3):



![image.png](data:image/png;base64,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)



Để phát hiện được outlier trong tập dữ liệu (dataset), chúng ta sẽ sử dụng biểu đồ hộp (box plot) nhé ! Để hiểu rõ hơn về box plot hãy xem video dưới đây:



[Biểu đồ hộp Box-plot](https://www.youtube.com/watch?v=eW7I2a0Bgs0)


```python
fig = sns.boxplot(data=df_new)

fig.set_xticks(range(5))

fig.set_xticklabels(['X2', 'X4', 'X5', 'X6', 'Y'])
```




    [Text(0, 0, 'X2'),
     Text(0, 0, 'X4'),
     Text(0, 0, 'X5'),
     Text(0, 0, 'X6'),
     Text(0, 0, 'Y')]




![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_19_1.png)


Qua biểu đồ hộp (box plot) của 4 biến không phụ thuộc (dependent variable), chúng ta thấy không có xuất hiện outlier ở ngoài khoảng min và max. Tuy nhiên ở biến phụ thuộc (dependent variable) chúng ta lại thấy có xuất hiện outlier, đây là các giá trị lớn hơn hẳn max của Y, chúng ta cần loại bỏ các cá thể (instance) này.


```python
# Tính Q1 và Q3 của từng biến trong tập dữ liệu (dataset)

q1 = df_new.quantile(0.25)

q3 = df_new.quantile(0.75)

# Tính IQR

iqr = q3 - q1

iqr
```




    X2 house age                       19.125000
    X4 number of convenience stores     5.000000
    X5 latitude                         0.014455
    X6 longitude                        0.015220
    Y house price of unit area         18.900000
    dtype: float64




```python
# Loại bỏ các cá thể có giá trị lớn hơn max và nhỏ hơn min của từng biến
df_without_outlier = df_new[~((df_new < (q1 - 1.5 * iqr)) |(df_new > (q3 + 1.5 * iqr))).any(axis=1)]

df_without_outlier
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>X2 house age</th>
      <th>X4 number of convenience stores</th>
      <th>X5 latitude</th>
      <th>X6 longitude</th>
      <th>Y house price of unit area</th>
    </tr>
    <tr>
      <th>No</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1</th>
      <td>32.0</td>
      <td>10</td>
      <td>24.98298</td>
      <td>121.54024</td>
      <td>37.9</td>
    </tr>
    <tr>
      <th>2</th>
      <td>19.5</td>
      <td>9</td>
      <td>24.98034</td>
      <td>121.53951</td>
      <td>42.2</td>
    </tr>
    <tr>
      <th>3</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>47.3</td>
    </tr>
    <tr>
      <th>4</th>
      <td>13.3</td>
      <td>5</td>
      <td>24.98746</td>
      <td>121.54391</td>
      <td>54.8</td>
    </tr>
    <tr>
      <th>5</th>
      <td>5.0</td>
      <td>5</td>
      <td>24.97937</td>
      <td>121.54245</td>
      <td>43.1</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>409</th>
      <td>18.5</td>
      <td>3</td>
      <td>24.96330</td>
      <td>121.51243</td>
      <td>28.1</td>
    </tr>
    <tr>
      <th>411</th>
      <td>5.6</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>50.0</td>
    </tr>
    <tr>
      <th>412</th>
      <td>18.8</td>
      <td>7</td>
      <td>24.97923</td>
      <td>121.53986</td>
      <td>40.6</td>
    </tr>
    <tr>
      <th>413</th>
      <td>8.1</td>
      <td>5</td>
      <td>24.96674</td>
      <td>121.54067</td>
      <td>52.5</td>
    </tr>
    <tr>
      <th>414</th>
      <td>6.5</td>
      <td>9</td>
      <td>24.97433</td>
      <td>121.54310</td>
      <td>63.9</td>
    </tr>
  </tbody>
</table>
<p>371 rows × 5 columns</p>
</div>



Kiểm tra lại biểu đồ hộp (box plot) sau khi đã loại trừ các giá trị ngoại biên (outlier).


```python
fig = sns.boxplot(data=df_without_outlier)

fig.set_xticks(range(5))

fig.set_xticklabels(['X2', 'X4', 'X5', 'X6', 'Y'])
```




    [Text(0, 0, 'X2'),
     Text(0, 0, 'X4'),
     Text(0, 0, 'X5'),
     Text(0, 0, 'X6'),
     Text(0, 0, 'Y')]




![png]({{ site.baseurl }}/img/in-post/aml/AI_with_Misa_Linear_Regression_24_1.png)


Do các giá trị ở biến không phụ thuộc (independent variable) không quá chênh lệch nhiều (hàng chục và đơn vị) nên chúng ta không cần phải chuẩn hóa (normalize). Tập dữ liệu (dataset) của chúng ta đã có thể tiến hành huấn luyện (training)

# **Phân chia tập dữ liệu**

Ở bước này chúng ta sẽ chia dữ liệu ra làm 2 tập nhỏ hơn, tập huấn luyện (training set) và tập xác nhận (validation set) với tỷ lệ 80% và 20%.

<span style='color: #f44336'>* random_state nhằm đảm bảo việc phân chia dữ liệu là như nhau trong mọi lần chạy.</span>

```python
y = df_without_outlier['Y house price of unit area']

y
```




    No
    1      37.9
    2      42.2
    3      47.3
    4      54.8
    5      43.1
           ... 
    409    28.1
    411    50.0
    412    40.6
    413    52.5
    414    63.9
    Name: Y house price of unit area, Length: 371, dtype: float64




```python
from sklearn.model_selection import train_test_split
```


```python
x_without_outlier = df_without_outlier.iloc[:,0:4]

X_train, X_valid, Y_train, Y_valid = train_test_split(x_without_outlier, y, test_size = 0.2, random_state = 101)
```

# **Huấn luyện regression model**


```python
from sklearn.linear_model import LinearRegression
```

Khởi tạo Linear Regression model


```python
regressor = LinearRegression()
```

Fit Linear Regression model vừa khởi tạo với tập dữ liệu huấn luyện (training set)


```python
regressor.fit(X_train, Y_train)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)



Xem các model parameter của model chúng ta vừa huấn huyện xong nhé


```python
regressor.coef_
```




    array([-3.03451439e-01,  1.44280883e+00,  4.58836606e+02,  2.63959238e+02])



Chúng ta có 4 trọng số (weight) tương ứng của 4 biến không phụ thuộc (independent variable): X2 house age, X4 number of convenience stores, X5 latitude,	X6 longitude


```python
regressor.intercept_
```




    -43499.661316731115



CÓ thể viết lại hàm số tuyến tính (linear function) của model của chúng ta sẽ như sau:



$y = -0.303X_{2} + 1.443X_{4} + 458.8X_{5} - 263.9X_{6} - 43499.66$

# **Kiểm tra Linear Regression đã huấn luyện** #


```python
pred = regressor.predict(X_valid)
```


```python
from sklearn.metrics import mean_squared_error

import math
```

Đầu tiên chúng ta sẽ tính Root Mean Square Error (RMSE)


```python
math.sqrt(mean_squared_error(Y_valid, pred))
```




    7.898845664720699



Sai số ở đây là khoảng 8\\$, tức là với mỗi giá nhà dự đoán chênh lệch so với thực tế (nhiều hơn hoặc ít hơn) 8\\$.

Một con chỉ khác chúng ta có thể tham khảo đó là $R^{2}$, đây là chỉ số miêu tả tỷ lệ phương sai (variance) của biến phụ thuộc (dependent variable) được giải thích (explain) bởi các biến không phụ thuộc (independent variable). Chỉ số $R^{2}$ nằm trong thang từ 0-1, càng gần 1 thì model càng chính xác.


```python
from sklearn.metrics import r2_score
```


```python
r2_score(Y_valid, pred)
```




    0.49820177247193564



Có thể thấy model của chúng ta không thật sự tốt, $R^{2}$ chỉ ở mức 0.49, có thể là do phân phối (distribution) của tập dữ liệu là phi tuyến tính (non linear).

# **Chuyển đổi sang Polynomial Regression**

Qua việc kiểm tra Linear Regression model đã huấn luyện, chúng ta có thể thấy kết quả không được như kỳ vọng, do đó để tăng hiệu năng của ML model, chúng ta cùng biến đổi các biến không phụ thuộc (independent variable) sang các đặc trưng (feature) Polynomial để xem có giúp cải thiện được hiệu năng không.


```python
from sklearn.preprocessing import PolynomialFeatures
```

Chúng ta sẽ chuyển đổi sang các biến không phụ thuộc (independent variable) sang các đặc trưng (feature) Polynomial bậc (degree) 3. 



Với việc biến đổi sang bậc (degree) 3, Polynomial Regression model chúng ta sẽ có các biến không phụ thuộc (independent variable):







*   Bias: 1

*   Bậc(Degree) 1: $X_{2}, X_{4}, X_{5}, X_{6}$

*   Bậc(Degree) 2: $X_{2}^{2}, X_{4}^{2}, X_{5}^{2}, X_{6}^{2}$

*   Bậc(Degree) 3: $X_{2}^{3}, X_{4}^{3}, X_{5}^{3}, X_{6}^{3}$

*   Tương tác (Interaction): $X_{2} \times X_{4}, X_{2} \times X_{5}, X_{4} \times X_{6},...$


```python
poly_feature  = PolynomialFeatures(degree= 3)

x_poly = poly_feature.fit_transform(x_without_outlier)
```


```python
import numpy as np
```


```python
x_poly = np.asarray(x_poly)

x_poly
```




    array([[1.00000000e+00, 3.20000000e+01, 1.00000000e+01, ...,
            7.58592545e+04, 3.69049329e+05, 1.79539606e+06],
           [1.00000000e+00, 1.95000000e+01, 9.00000000e+00, ...,
            7.58427674e+04, 3.69005898e+05, 1.79536371e+06],
           [1.00000000e+00, 1.33000000e+01, 5.00000000e+00, ...,
            7.58887548e+04, 3.69137799e+05, 1.79555871e+06],
           ...,
           [1.00000000e+00, 1.88000000e+01, 7.00000000e+00, ...,
            7.58362458e+04, 3.68991626e+05, 1.79537922e+06],
           [1.00000000e+00, 8.10000000e+00, 5.00000000e+00, ...,
            7.57609311e+04, 3.68812040e+05, 1.79541512e+06],
           [1.00000000e+00, 6.50000000e+00, 9.00000000e+00, ...,
            7.58085170e+04, 3.68938913e+05, 1.79552281e+06]])



Cũng như ở trên chúng ta cũng sẽ chia ra hai tập dữ liệu nhỏ hơn, một tập để huấn luyện (training set), một tập để xác nhận (validation set)


```python
X_train_poly, X_valid_poly, Y_train_poly, Y_valid_poly = train_test_split(x_poly, y, test_size = 0.2, random_state = 101)
```

Lưu ý là chúng ta vẫn sử dụng Linear Regression, nhưng chỉ khác là chúng ta sẽ fit nó với các đặc trưng (feature) Polynomial vừa tạo ra ở trên


```python
poly_regressor = LinearRegression()
```


```python
poly_regressor.fit(X_train_poly, Y_train_poly)
```




    LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)



Kiểm tra hiệu năng của Polynomial Regression vừa tạo ra nhé


```python
pred = poly_regressor.predict(X_valid_poly)
```


```python
math.sqrt(mean_squared_error(Y_valid_poly, pred))
```




    6.1589550610291335




```python
r2_score(Y_valid_poly, pred)
```




    0.6949184550706298



Có thể thấy ML model của chúng ta đã được cải thiện lên rất nhiều, RMSE giảm xuống còn 6\\$, trong khó đi $R_{2}$ tăng lên 0.695 !  

Các bạn có thể thay đổi các thông số trong quá trình huấn luyện (training) như bậc của các đặc trưng (feature) Polynomial, không loại bỏ biến X3 distance to the nearest MRT station,... Sau đó comment ở dưới bài viết này để xem sự khác biệt nhé 😁

