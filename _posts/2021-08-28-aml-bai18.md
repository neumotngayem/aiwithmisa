---
layout: post
title: "[Thực hành] Bài 18 Phân cụm k-Means - k-Means Clustering"
subtitle: "Loạt bài học thuộc series AML"
date: 2021-08-28
author: "KyoHB"
header-img: "img/post-bg-aml.jpg"
tags: [AML]
---

Trong bài thực hành cuối của series AML cùng AI with Misa, chúng ta sẽ thực hành phân cụm k-Means thông qua thư viện sklearn nhé.

# **Import tập dữ liệu**

Trong bài thực hành này chúng ta, sẽ sử dụng một tập dữ liệu (dataset) khá kinh điển và lão thành đó là iris dataset. Tập dữ liệu (dataset) này gồm 150 điểm dữ liệu (sample) về 4 đặc tính của hoa Diên vĩ.

![]({{ site.baseurl }}/img/in-post/aml/iris.jpg)


```python
from sklearn.datasets import load_iris
data = load_iris()
```

Chúng ta cùng xem data vừa load được có cấu trúc như nào nhé:


```python
data
```




    {'DESCR': '.. _iris_dataset:\n\nIris plants dataset\n--------------------\n\n**Data Set Characteristics:**\n\n    :Number of Instances: 150 (50 in each of three classes)\n    :Number of Attributes: 4 numeric, predictive attributes and the class\n    :Attribute Information:\n        - sepal length in cm\n        - sepal width in cm\n        - petal length in cm\n        - petal width in cm\n        - class:\n                - Iris-Setosa\n                - Iris-Versicolour\n                - Iris-Virginica\n                \n    :Summary Statistics:\n\n    ============== ==== ==== ======= ===== ====================\n                    Min  Max   Mean    SD   Class Correlation\n    ============== ==== ==== ======= ===== ====================\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n    ============== ==== ==== ======= ===== ====================\n\n    :Missing Attribute Values: None\n    :Class Distribution: 33.3% for each of 3 classes.\n    :Creator: R.A. Fisher\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n    :Date: July, 1988\n\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\nfrom Fisher\'s paper. Note that it\'s the same as in R, but not as in the UCI\nMachine Learning Repository, which has two wrong data points.\n\nThis is perhaps the best known database to be found in the\npattern recognition literature.  Fisher\'s paper is a classic in the field and\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\ndata set contains 3 classes of 50 instances each, where each class refers to a\ntype of iris plant.  One class is linearly separable from the other 2; the\nlatter are NOT linearly separable from each other.\n\n.. topic:: References\n\n   - Fisher, R.A. "The use of multiple measurements in taxonomic problems"\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in "Contributions to\n     Mathematical Statistics" (John Wiley, NY, 1950).\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n   - Dasarathy, B.V. (1980) "Nosing Around the Neighborhood: A New System\n     Structure and Classification Rule for Recognition in Partially Exposed\n     Environments".  IEEE Transactions on Pattern Analysis and Machine\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n   - Gates, G.W. (1972) "The Reduced Nearest Neighbor Rule".  IEEE Transactions\n     on Information Theory, May 1972, 431-433.\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al"s AUTOCLASS II\n     conceptual clustering system finds 3 classes in the data.\n   - Many, many more ...',
     'data': array([[5.1, 3.5, 1.4, 0.2],
            [4.9, 3. , 1.4, 0.2],
            [4.7, 3.2, 1.3, 0.2],
            [4.6, 3.1, 1.5, 0.2],
            [5. , 3.6, 1.4, 0.2],
            [5.4, 3.9, 1.7, 0.4],
            [4.6, 3.4, 1.4, 0.3],
            [5. , 3.4, 1.5, 0.2],
            [4.4, 2.9, 1.4, 0.2],
            [4.9, 3.1, 1.5, 0.1],
            [5.4, 3.7, 1.5, 0.2],
            [4.8, 3.4, 1.6, 0.2],
            [4.8, 3. , 1.4, 0.1],
            [4.3, 3. , 1.1, 0.1],
            [5.8, 4. , 1.2, 0.2],
            [5.7, 4.4, 1.5, 0.4],
            [5.4, 3.9, 1.3, 0.4],
            [5.1, 3.5, 1.4, 0.3],
            [5.7, 3.8, 1.7, 0.3],
            [5.1, 3.8, 1.5, 0.3],
            [5.4, 3.4, 1.7, 0.2],
            [5.1, 3.7, 1.5, 0.4],
            [4.6, 3.6, 1. , 0.2],
            [5.1, 3.3, 1.7, 0.5],
            [4.8, 3.4, 1.9, 0.2],
            [5. , 3. , 1.6, 0.2],
            [5. , 3.4, 1.6, 0.4],
            [5.2, 3.5, 1.5, 0.2],
            [5.2, 3.4, 1.4, 0.2],
            [4.7, 3.2, 1.6, 0.2],
            [4.8, 3.1, 1.6, 0.2],
            [5.4, 3.4, 1.5, 0.4],
            [5.2, 4.1, 1.5, 0.1],
            [5.5, 4.2, 1.4, 0.2],
            [4.9, 3.1, 1.5, 0.2],
            [5. , 3.2, 1.2, 0.2],
            [5.5, 3.5, 1.3, 0.2],
            [4.9, 3.6, 1.4, 0.1],
            [4.4, 3. , 1.3, 0.2],
            [5.1, 3.4, 1.5, 0.2],
            [5. , 3.5, 1.3, 0.3],
            [4.5, 2.3, 1.3, 0.3],
            [4.4, 3.2, 1.3, 0.2],
            [5. , 3.5, 1.6, 0.6],
            [5.1, 3.8, 1.9, 0.4],
            [4.8, 3. , 1.4, 0.3],
            [5.1, 3.8, 1.6, 0.2],
            [4.6, 3.2, 1.4, 0.2],
            [5.3, 3.7, 1.5, 0.2],
            [5. , 3.3, 1.4, 0.2],
            [7. , 3.2, 4.7, 1.4],
            [6.4, 3.2, 4.5, 1.5],
            [6.9, 3.1, 4.9, 1.5],
            [5.5, 2.3, 4. , 1.3],
            [6.5, 2.8, 4.6, 1.5],
            [5.7, 2.8, 4.5, 1.3],
            [6.3, 3.3, 4.7, 1.6],
            [4.9, 2.4, 3.3, 1. ],
            [6.6, 2.9, 4.6, 1.3],
            [5.2, 2.7, 3.9, 1.4],
            [5. , 2. , 3.5, 1. ],
            [5.9, 3. , 4.2, 1.5],
            [6. , 2.2, 4. , 1. ],
            [6.1, 2.9, 4.7, 1.4],
            [5.6, 2.9, 3.6, 1.3],
            [6.7, 3.1, 4.4, 1.4],
            [5.6, 3. , 4.5, 1.5],
            [5.8, 2.7, 4.1, 1. ],
            [6.2, 2.2, 4.5, 1.5],
            [5.6, 2.5, 3.9, 1.1],
            [5.9, 3.2, 4.8, 1.8],
            [6.1, 2.8, 4. , 1.3],
            [6.3, 2.5, 4.9, 1.5],
            [6.1, 2.8, 4.7, 1.2],
            [6.4, 2.9, 4.3, 1.3],
            [6.6, 3. , 4.4, 1.4],
            [6.8, 2.8, 4.8, 1.4],
            [6.7, 3. , 5. , 1.7],
            [6. , 2.9, 4.5, 1.5],
            [5.7, 2.6, 3.5, 1. ],
            [5.5, 2.4, 3.8, 1.1],
            [5.5, 2.4, 3.7, 1. ],
            [5.8, 2.7, 3.9, 1.2],
            [6. , 2.7, 5.1, 1.6],
            [5.4, 3. , 4.5, 1.5],
            [6. , 3.4, 4.5, 1.6],
            [6.7, 3.1, 4.7, 1.5],
            [6.3, 2.3, 4.4, 1.3],
            [5.6, 3. , 4.1, 1.3],
            [5.5, 2.5, 4. , 1.3],
            [5.5, 2.6, 4.4, 1.2],
            [6.1, 3. , 4.6, 1.4],
            [5.8, 2.6, 4. , 1.2],
            [5. , 2.3, 3.3, 1. ],
            [5.6, 2.7, 4.2, 1.3],
            [5.7, 3. , 4.2, 1.2],
            [5.7, 2.9, 4.2, 1.3],
            [6.2, 2.9, 4.3, 1.3],
            [5.1, 2.5, 3. , 1.1],
            [5.7, 2.8, 4.1, 1.3],
            [6.3, 3.3, 6. , 2.5],
            [5.8, 2.7, 5.1, 1.9],
            [7.1, 3. , 5.9, 2.1],
            [6.3, 2.9, 5.6, 1.8],
            [6.5, 3. , 5.8, 2.2],
            [7.6, 3. , 6.6, 2.1],
            [4.9, 2.5, 4.5, 1.7],
            [7.3, 2.9, 6.3, 1.8],
            [6.7, 2.5, 5.8, 1.8],
            [7.2, 3.6, 6.1, 2.5],
            [6.5, 3.2, 5.1, 2. ],
            [6.4, 2.7, 5.3, 1.9],
            [6.8, 3. , 5.5, 2.1],
            [5.7, 2.5, 5. , 2. ],
            [5.8, 2.8, 5.1, 2.4],
            [6.4, 3.2, 5.3, 2.3],
            [6.5, 3. , 5.5, 1.8],
            [7.7, 3.8, 6.7, 2.2],
            [7.7, 2.6, 6.9, 2.3],
            [6. , 2.2, 5. , 1.5],
            [6.9, 3.2, 5.7, 2.3],
            [5.6, 2.8, 4.9, 2. ],
            [7.7, 2.8, 6.7, 2. ],
            [6.3, 2.7, 4.9, 1.8],
            [6.7, 3.3, 5.7, 2.1],
            [7.2, 3.2, 6. , 1.8],
            [6.2, 2.8, 4.8, 1.8],
            [6.1, 3. , 4.9, 1.8],
            [6.4, 2.8, 5.6, 2.1],
            [7.2, 3. , 5.8, 1.6],
            [7.4, 2.8, 6.1, 1.9],
            [7.9, 3.8, 6.4, 2. ],
            [6.4, 2.8, 5.6, 2.2],
            [6.3, 2.8, 5.1, 1.5],
            [6.1, 2.6, 5.6, 1.4],
            [7.7, 3. , 6.1, 2.3],
            [6.3, 3.4, 5.6, 2.4],
            [6.4, 3.1, 5.5, 1.8],
            [6. , 3. , 4.8, 1.8],
            [6.9, 3.1, 5.4, 2.1],
            [6.7, 3.1, 5.6, 2.4],
            [6.9, 3.1, 5.1, 2.3],
            [5.8, 2.7, 5.1, 1.9],
            [6.8, 3.2, 5.9, 2.3],
            [6.7, 3.3, 5.7, 2.5],
            [6.7, 3. , 5.2, 2.3],
            [6.3, 2.5, 5. , 1.9],
            [6.5, 3. , 5.2, 2. ],
            [6.2, 3.4, 5.4, 2.3],
            [5.9, 3. , 5.1, 1.8]]),
     'feature_names': ['sepal length (cm)',
      'sepal width (cm)',
      'petal length (cm)',
      'petal width (cm)'],
     'filename': '/usr/local/lib/python3.7/dist-packages/sklearn/datasets/data/iris.csv',
     'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
            0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
            1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
            2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,
            2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),
     'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10')}



Như vậy chúng ta có trường data chứa dữ liệu gồm 4 đặc trưng (feature) chiều dài, rộng của lá đài (sepal), chiều dài, rộng của cánh hoa (petal). Hoa diên vĩ được chia là 3 loài chính là setosa, versicolor, virginica. Trường target chính là các nhóm (class) tương ứng của các điểm dữ liệu. 

# **Biểu đồ Silohuette**

Khi thực hiện phân cụm theo phần (partitional) nói chung và phân cụm K-means nói riêng, chúng ta cần phải xác định trước số cụm (cluster). Giả sử với tập dữ liệu (dataset) hoa diên vĩ ở trên chúng ta không biết trước là gồm 3 loài hoa, làm sao để chúng ta biết nên chia chúng thành mấy cụm ? Để làm được việc này chúng ta sẽ sử dụng biểu đồ Silohouette. Biểu đồ Silohouette là phương pháp biểu thị và xác nhận mức độ ổn định các các điểm dữ liệu (sample) trong cùng một cụm. Mỗi điểm dữ liệu (sample) sẽ được tính giá trị Silohouette, nó có giá trị từ -1 đến 1, với giá trị càng cao (càng gần 1) thì biểu thị mức độ tương đồng của nó với các cá thể trong cùng một cụm càng cao, đồng thời khác biệt lớn với các cá thể ở cụm khác. 

![]({{ site.baseurl }}/img/in-post/aml/silohuette.png) *Source: vitalflux.com*
{:.image-caption}


# **Phân cụm K-means**

Với tập dữ liệu trên, chúng ta sẽ thử chia ra thành 2,3,4,5 cụm và phân tích xem số cụm nào là thích hợp nhờ biểu đồ Silohute nhé. Nhằm tiện cho việc trực quan hóa việc phân cụm dữ liệu, chúng ta sẽ chỉ sử dụng đặc trưng chiều dài, rộng của lá đài (sepal). 


```python
# Lấy 2 cột đầu của tất cả các dòng dữ liệu
data = data['data'][:,:2]
data
```




    array([[5.1, 3.5],
           [4.9, 3. ],
           [4.7, 3.2],
           [4.6, 3.1],
           [5. , 3.6],
           [5.4, 3.9],
           [4.6, 3.4],
           [5. , 3.4],
           [4.4, 2.9],
           [4.9, 3.1],
           [5.4, 3.7],
           [4.8, 3.4],
           [4.8, 3. ],
           [4.3, 3. ],
           [5.8, 4. ],
           [5.7, 4.4],
           [5.4, 3.9],
           [5.1, 3.5],
           [5.7, 3.8],
           [5.1, 3.8],
           [5.4, 3.4],
           [5.1, 3.7],
           [4.6, 3.6],
           [5.1, 3.3],
           [4.8, 3.4],
           [5. , 3. ],
           [5. , 3.4],
           [5.2, 3.5],
           [5.2, 3.4],
           [4.7, 3.2],
           [4.8, 3.1],
           [5.4, 3.4],
           [5.2, 4.1],
           [5.5, 4.2],
           [4.9, 3.1],
           [5. , 3.2],
           [5.5, 3.5],
           [4.9, 3.6],
           [4.4, 3. ],
           [5.1, 3.4],
           [5. , 3.5],
           [4.5, 2.3],
           [4.4, 3.2],
           [5. , 3.5],
           [5.1, 3.8],
           [4.8, 3. ],
           [5.1, 3.8],
           [4.6, 3.2],
           [5.3, 3.7],
           [5. , 3.3],
           [7. , 3.2],
           [6.4, 3.2],
           [6.9, 3.1],
           [5.5, 2.3],
           [6.5, 2.8],
           [5.7, 2.8],
           [6.3, 3.3],
           [4.9, 2.4],
           [6.6, 2.9],
           [5.2, 2.7],
           [5. , 2. ],
           [5.9, 3. ],
           [6. , 2.2],
           [6.1, 2.9],
           [5.6, 2.9],
           [6.7, 3.1],
           [5.6, 3. ],
           [5.8, 2.7],
           [6.2, 2.2],
           [5.6, 2.5],
           [5.9, 3.2],
           [6.1, 2.8],
           [6.3, 2.5],
           [6.1, 2.8],
           [6.4, 2.9],
           [6.6, 3. ],
           [6.8, 2.8],
           [6.7, 3. ],
           [6. , 2.9],
           [5.7, 2.6],
           [5.5, 2.4],
           [5.5, 2.4],
           [5.8, 2.7],
           [6. , 2.7],
           [5.4, 3. ],
           [6. , 3.4],
           [6.7, 3.1],
           [6.3, 2.3],
           [5.6, 3. ],
           [5.5, 2.5],
           [5.5, 2.6],
           [6.1, 3. ],
           [5.8, 2.6],
           [5. , 2.3],
           [5.6, 2.7],
           [5.7, 3. ],
           [5.7, 2.9],
           [6.2, 2.9],
           [5.1, 2.5],
           [5.7, 2.8],
           [6.3, 3.3],
           [5.8, 2.7],
           [7.1, 3. ],
           [6.3, 2.9],
           [6.5, 3. ],
           [7.6, 3. ],
           [4.9, 2.5],
           [7.3, 2.9],
           [6.7, 2.5],
           [7.2, 3.6],
           [6.5, 3.2],
           [6.4, 2.7],
           [6.8, 3. ],
           [5.7, 2.5],
           [5.8, 2.8],
           [6.4, 3.2],
           [6.5, 3. ],
           [7.7, 3.8],
           [7.7, 2.6],
           [6. , 2.2],
           [6.9, 3.2],
           [5.6, 2.8],
           [7.7, 2.8],
           [6.3, 2.7],
           [6.7, 3.3],
           [7.2, 3.2],
           [6.2, 2.8],
           [6.1, 3. ],
           [6.4, 2.8],
           [7.2, 3. ],
           [7.4, 2.8],
           [7.9, 3.8],
           [6.4, 2.8],
           [6.3, 2.8],
           [6.1, 2.6],
           [7.7, 3. ],
           [6.3, 3.4],
           [6.4, 3.1],
           [6. , 3. ],
           [6.9, 3.1],
           [6.7, 3.1],
           [6.9, 3.1],
           [5.8, 2.7],
           [6.8, 3.2],
           [6.7, 3.3],
           [6.7, 3. ],
           [6.3, 2.5],
           [6.5, 3. ],
           [6.2, 3.4],
           [5.9, 3. ]])




```python
# Hàm vẽ biểu đồ silohuette (source code from sklearn)
def draw_silohuette_diagram(axes, cluster_num, cluster_result, silhouette_values, silhouette_avg):
    y_lower = 10
    cluster_color = ['#8B0000', '#FFA500', '#228B22', '#1E90FF', '#8B008B']
    for i in range(cluster_num):
        # Tổng hợp silohuette score của các thành phần trong cụm
        ith_cluster_silhouette_values = silhouette_values[cluster_result == i]

        ith_cluster_silhouette_values.sort()

        size_cluster_i = ith_cluster_silhouette_values.shape[0]
        y_upper = y_lower + size_cluster_i

        #color = cm.nipy_spectral(float(i) / cluster_num)
        axes.fill_betweenx(np.arange(y_lower, y_upper),
                          0, ith_cluster_silhouette_values,
                          facecolor=cluster_color[i], edgecolor=cluster_color[i], alpha=0.7)

        # Biểu thị tên nhóm
        axes.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))

        # Tính toán vị trí cho tên nhóm tiếp theo
        y_lower = y_upper + 10  # 10 for the 0 samples

    axes.set_title("Biểu đồ silohuette của nhóm {} - {}".format(cluster_num, silhouette_avg))
    axes.set_xlabel("Hệ số silhouette")
    axes.set_ylabel("Cụm")

    # Vạch trung bình silohuette score
    axes.axvline(x=silhouette_avg, color="red", linestyle="--")

    axes.set_yticks([])
    axes.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])
```


```python
# Hàm vẽ biểu đồ silohuette (source code from sklearn)
def draw_scatter_plot(axes, cluster_num, data, cluster_result, centers):
  cluster_color = ['#8B0000', '#FFA500', '#228B22', '#1E90FF', '#8B008B']
  for idx, (sepal_len, sepal_wid) in enumerate(data):
    cluster_label = cluster_result[idx]
    axes.scatter(sepal_len, sepal_wid, marker='.',c=cluster_color[cluster_label], alpha=0.7)
  # Trọng tâm của cụm
  axes.scatter(centers[:,0], centers[:,1], marker='o', c='white', s=200, edgecolor='black')
  for idx_center, c in enumerate(centers):
      axes.scatter(c[0], c[1], marker='${}$'.format(idx_center), alpha=1,
                  s=50, edgecolor='k')

  axes.set_title('Biểu đồ scatter của nhóm {}'.format(cluster_num))
  axes.set_xlabel('Chiều dài lá đài (sepal length)')
  axes.set_ylabel('Chiều rộng lá đài (sepal width)')
```


```python
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_samples, silhouette_score
import numpy as np

# Phân cụm dữ liệu thành 2,3,4,5 cụm
for i in range(2,6):
  # Phân cụm k-Means
  kmeans_clusterer = KMeans(n_clusters=i, random_state=99)
  # Phân cụm với dữ liệu về lá đài
  cluster_result = kmeans_clusterer.fit_predict(data)
  # Lấy trọng tâm của của các cụm sau khi phân cụm
  centers = kmeans_clusterer.cluster_centers_
  # Tính silhouette score trung bình toàn dữ liệu
  silhouette_avg = silhouette_score(data, cluster_result)
  # Lấy silhouette score của từng điểm dữ liệu
  silhouette_values = silhouette_samples(data,cluster_result)
  # Vẽ biểu đồ silhouette và scatter các điểm dữ liệu
  fig, (axes1, axes2) = plt.subplots(1,2)
  fig.set_size_inches(18,7)
  draw_silohuette_diagram(axes1, i, cluster_result, silhouette_values, silhouette_avg)
  draw_scatter_plot(axes2, i, data, cluster_result, centers)
```


    
![png]({{ site.baseurl }}/img/in-post/aml/AI_With_Misa_k_Means_14_0.png)
    



    
![png]({{ site.baseurl }}/img/in-post/aml/AI_With_Misa_k_Means_14_1.png)
    



    
![png]({{ site.baseurl }}/img/in-post/aml/AI_With_Misa_k_Means_14_2.png)
    



    
![png]({{ site.baseurl }}/img/in-post/aml/AI_With_Misa_k_Means_14_3.png)
    


# **Kết**

Qua phần vẽ biểu đồ sihouette trên chúng ta thấy khi phân dữ liệu ra làm 2 và 3 cụm sẽ được điểm số silhouette trung bình cao nhất. Tuy nhiên khi phân thành 2 cụm, số thành viên của 2 cụm không đồng đều với nhau, cụm 0 dày hơn so với cụm 1. Ở cụm 0, số lượng cá thể ở dưới mức silhouette trung bình là khá nhiều. Bên cạnh đó qua biểu đồ scatter chúng ta có thể thấy 2 cụm này khá sát nhau, làm cho điểm số silhouette của một số điểm dữ liệu ở cụm 0 có giá trị âm. Dữ liệu tốt nhất nên được phân làm 3 cụm, đúng như nhãn nguyên thủy của tập dữ liệu (dataset). Tuy nhiên cũng có thể thấy khi phân làm 3 cụm, ngoài cụm 2 tách biệt với các cụm còn lại, cụm 0 và 1 vẫn tồn tại vùng giáp ranh với nhau làm cho kha khá các cá thể ở cụm 0 có điểm số silhouette dưới mức trung bình.
